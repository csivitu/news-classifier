{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAn1N-z5L6J5",
        "outputId": "12adad90-2a23-481d-ffc1-2e9405befde4"
      },
      "outputs": [],
      "source": [
        "!pip install pandas scikit-learn nltk "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIlPE7hyL8EA",
        "outputId": "be68a6e8-a116-440f-a9ee-b9d3a2a8f660"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import time\n",
        "\n",
        "\n",
        "from nltk import pos_tag\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer as lemmatizer\n",
        "from spellchecker import SpellChecker\n",
        "\n",
        "\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0ShVjRtpL8Rm"
      },
      "outputs": [],
      "source": [
        "file_path = 'News_Category_Dataset_v3.json'\n",
        "df2 = pd.read_json(\"News_Category_Dataset_v3.json\", lines=True)\n",
        "df2['text'] = df2['headline'] + \" \" + df2['short_description']\n",
        "df2 = df2[['category', 'text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EuQaXpTJL8X6"
      },
      "outputs": [],
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "\n",
        "    tokens = re.sub(r'[^a-z\\s]', '', text)\n",
        "    tokens = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    tokens = re.sub(r'<.*?>', '', text)\n",
        "    tokens = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)\n",
        "    tokens = [\n",
        "        token if pos_tag([token])[0][1] != 'NNP'\n",
        "        else token for token in tokens\n",
        "        if token.isalpha() and token not in stop_words\n",
        "        ]\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    spell = SpellChecker()\n",
        "    tokens = [spell.correction(token) for token in tokens]\n",
        "\n",
        "    return ' '.join(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "id": "dvuPlZEUMTW7"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'processed_text'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\Oxide-1\\Documents\\Forkthis graVITas\\Forkthis\\New folder\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'processed_text'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mdf2\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprocessed_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m], test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m)\n\u001b[0;32m      3\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m      4\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf\u001b[39m\u001b[38;5;124m'\u001b[39m, TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)),\n\u001b[0;32m      5\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, MultinomialNB()),\n\u001b[0;32m      6\u001b[0m ])\n",
            "File \u001b[1;32mc:\\Users\\Oxide-1\\Documents\\Forkthis graVITas\\Forkthis\\New folder\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[1;32mc:\\Users\\Oxide-1\\Documents\\Forkthis graVITas\\Forkthis\\New folder\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'processed_text'"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df2['processed_text'], df2['category'], test_size=0.6)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(max_features=5000)),\n",
        "    ('classifier', MultinomialNB()),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnAY78liT977",
        "outputId": "ebd700c0-c2ac-4559-d482-454d3e5af814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training the model...\n",
            "Training completed in 2.38 seconds (0.04 minutes)\n",
            "Making predictions...\n",
            "Accuracy: 0.4929\n",
            "\n",
            "Classification Report:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "          ARTS       0.57      0.01      0.03       893\n",
            "ARTS & CULTURE       1.00      0.00      0.00       804\n",
            "  BLACK VOICES       0.60      0.07      0.12      2751\n",
            "      BUSINESS       0.50      0.23      0.32      3628\n",
            "       COLLEGE       0.67      0.00      0.01       716\n",
            "        COMEDY       0.66      0.20      0.31      3191\n",
            "         CRIME       0.55      0.42      0.48      2149\n",
            "CULTURE & ARTS       0.92      0.04      0.07       627\n",
            "       DIVORCE       0.89      0.40      0.55      2099\n",
            "     EDUCATION       0.80      0.01      0.01       603\n",
            " ENTERTAINMENT       0.44      0.76      0.56     10504\n",
            "   ENVIRONMENT       1.00      0.05      0.10       827\n",
            "         FIFTY       1.00      0.00      0.00       831\n",
            "  FOOD & DRINK       0.57      0.67      0.61      3773\n",
            "     GOOD NEWS       1.00      0.01      0.02       850\n",
            "         GREEN       0.46      0.07      0.12      1570\n",
            "HEALTHY LIVING       0.50      0.02      0.04      4047\n",
            " HOME & LIVING       0.82      0.43      0.56      2620\n",
            "        IMPACT       0.57      0.06      0.11      2084\n",
            " LATINO VOICES       0.88      0.01      0.02       622\n",
            "         MEDIA       0.79      0.06      0.11      1757\n",
            "         MONEY       0.65      0.05      0.10      1055\n",
            "     PARENTING       0.43      0.55      0.48      5292\n",
            "       PARENTS       0.69      0.02      0.05      2450\n",
            "      POLITICS       0.48      0.93      0.63     21257\n",
            "  QUEER VOICES       0.77      0.39      0.52      3796\n",
            "      RELIGION       0.74      0.12      0.20      1590\n",
            "       SCIENCE       0.83      0.12      0.21      1313\n",
            "        SPORTS       0.69      0.40      0.51      3021\n",
            "         STYLE       1.00      0.00      0.00      1309\n",
            "STYLE & BEAUTY       0.62      0.74      0.67      5931\n",
            "         TASTE       1.00      0.00      0.00      1235\n",
            "          TECH       0.78      0.08      0.14      1301\n",
            " THE WORLDPOST       0.49      0.23      0.31      2193\n",
            "        TRAVEL       0.56      0.76      0.64      5885\n",
            "     U.S. NEWS       1.00      0.00      0.00       820\n",
            "      WEDDINGS       0.87      0.51      0.64      2170\n",
            "    WEIRD NEWS       0.52      0.05      0.08      1688\n",
            "      WELLNESS       0.39      0.87      0.54     10854\n",
            "         WOMEN       0.64      0.08      0.14      2123\n",
            "    WORLD NEWS       0.51      0.11      0.18      1974\n",
            "     WORLDPOST       0.58      0.03      0.06      1514\n",
            "\n",
            "      accuracy                           0.49    125717\n",
            "     macro avg       0.70      0.23      0.24    125717\n",
            "  weighted avg       0.58      0.49      0.42    125717\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Training the model...\")\n",
        "start_time = time.time()\n",
        "pipeline.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "training_time = end_time - start_time\n",
        "print(f\"Training completed in {training_time:.2f} seconds ({training_time/60:.2f} minutes)\")\n",
        "\n",
        "print(\"Making predictions...\")\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.4f}\\n\")\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, zero_division=1))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
